{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_nlp_ mscoco.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Eh6jEKTbPHbf",
        "colab_type": "code",
        "outputId": "3439acb1-a465-4abf-a6b5-8ba87ca7c598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-hub\n",
        "!pip install -q gensim\n",
        "!pip install -q sklearn\n",
        "!pip install -q matplotlib\n",
        "!apt-get install -qq jq\n",
        "!wget -nc -c https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘wiki.en.vec’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPWVkeCn0_pt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download and unpack the annotations from the 2014 MSCOCO dataset. This has 100k+ human-entered image captions. Each is a short declarative sentence. \n",
        "\n",
        "This dataset has shallow linguistic depth but a lot of vocabulary.\n",
        "\n",
        "**jq** is a super-fast streaming JSON parser app."
      ]
    },
    {
      "metadata": {
        "id": "xP9UuuEKQM9q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -c -nc -q http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip -p annotations_trainval2014.zip annotations/captions_train2014.json > captions_train2014.json\n",
        "!jq -r '.annotations[]|.caption' < captions_train2014.json > sentences.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H9yH0ejlFJXH",
        "colab_type": "code",
        "outputId": "05e804c1-238f-4d1f-d073-e4053a44418c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "from scipy.stats import norm\n",
        "from sklearn.decomposition import PCA\n",
        "import nltk.data\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import reuters\n",
        "from nltk. corpus import gutenberg\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import FastText\n",
        "from keras.layers import Input, Dense, Lambda, Layer\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('reuters')\n",
        "nltk.download('gutenberg')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ec9vwJMFJXL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Text"
      ]
    },
    {
      "metadata": {
        "id": "qfUeAb3iFJXM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The preprocessing code is data specific.  \n",
        "  \n",
        "It is an example of how one can use a pre-trained word2vec to embed sentences into a vector space."
      ]
    },
    {
      "metadata": {
        "id": "6R9JKPPMywFh",
        "colab_type": "code",
        "outputId": "0ebc9951-bd6a-4a74-8b94-f9f6c1e53e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# A little tight on RAM, so parse word2vec, save object to disk, memory-map object back into RAM.\n",
        "# Now the OS can drop the space whenever it is not being read.\n",
        "w2v = None\n",
        "if not os.path.exists('/content/wiki.en.vec.kv'):\n",
        "    print('Read word2vec vectors from text')\n",
        "    w2v = KeyedVectors.load_word2vec_format('/content/wiki.en.vec')\n",
        "    print('Save word2vec vectors to cache')\n",
        "    w2v.save('/content/wiki.en.vec.kv')\n",
        "else:\n",
        "    print('Using cached word2vec vectors')\n",
        "    w2v = KeyedVectors.load('/content/wiki.en.vec.kv', mmap='r')\n",
        "embedding_size = len(w2v['and'])\n",
        "embedding_size"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached word2vec vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "VlbYoXzbyv7r",
        "colab_type": "code",
        "outputId": "84f27acc-905c-48c7-fba8-3b134bbbab13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -ld /content\n",
        "!ls -l /content"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drwxr-xr-x 1 root root 4096 Dec 16 02:36 /content\n",
            "total 9951480\n",
            "-rw-r--r-- 1 root root    1335768 Dec 16 02:35 10words.pk\n",
            "-rw-r--r-- 1 root root  252872794 Jul 10 17:58 annotations_trainval2014.zip\n",
            "-rw-r--r-- 1 root root   66782097 Dec 16 02:37 captions_train2014.json\n",
            "-rw-r--r-- 1 root root   86494824 Dec 16 02:36 model.h5\n",
            "drwxr-xr-x 1 root root       4096 Dec 10 17:34 sample_data\n",
            "-rw-r--r-- 1 root root   22159544 Dec 16 02:37 sentences.txt\n",
            "-rw-r--r-- 1 root root 6597238061 May  2  2017 wiki.en.vec\n",
            "-rw-r--r-- 1 root root  140148778 Dec 16 02:08 wiki.en.vec.kv\n",
            "-rw-r--r-- 1 root root 3023244128 Dec 16 02:08 wiki.en.vec.kv.vectors.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H6dnQZWYPEbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "gNYrPq4ZFJXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def token_sent (text):\n",
        "    #strg = ''\n",
        "    #for word in text:\n",
        "    #    strg += word\n",
        "    #    strg += ' '\n",
        "    strg_cleaned = text.lower()\n",
        "    for x in ['\\xd5d','\\n','\"',\"!\", '#','$','%','&','(',')','*','+',',','-','/',':',';','<','=','>','?','@','[','^',']','_','`','{','|','}','~','\\t']:\n",
        "        strg_cleaned = strg_cleaned.replace(x, '')\n",
        "    sentences = sent_tokenize(strg_cleaned)\n",
        "    return sentences\n",
        "\n",
        "def split_into_sent (text):\n",
        "    strg = ''\n",
        "    for word in text:\n",
        "        strg += word\n",
        "        strg += ' '\n",
        "    strg_cleaned = strg.lower()\n",
        "    for x in ['\\xd5d','\\n','\"',\"!\", '#','$','%','&','(',')','*','+',',','-','/',':',';','<','=','>','?','@','[','^',']','_','`','{','|','}','~','\\t']:\n",
        "        strg_cleaned = strg_cleaned.replace(x, '')\n",
        "    sentences = sent_tokenize(strg_cleaned)\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1S7J4beFJXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxindex = -1\n",
        "def vectorize_sentences(sentences):\n",
        "    vectorized = []\n",
        "    for sentence in sentences:\n",
        "        if sentence[-1] == '.':\n",
        "            sentence = sentence[:-1]\n",
        "        byword = sentence.split()\n",
        "        concat_vector = []\n",
        "        for word in byword:\n",
        "            #print(word)\n",
        "            try:\n",
        "                concat_vector.append(w2v[word])\n",
        "            except:\n",
        "                #print('fail on {}'.format(word))\n",
        "                pass\n",
        "        vectorized.append(concat_vector)\n",
        "    return vectorized\n",
        "\n",
        "def wordify(sentence):\n",
        "    if sentence[-1] == '.':\n",
        "        sentence = sentence[:-1]\n",
        "    byword = sentence.split()\n",
        "    for word in byword:\n",
        "        if not word in w2v:\n",
        "            return None\n",
        "    return byword\n",
        "\n",
        "def vectorize_sentence(sentence):\n",
        "    vector = []\n",
        "    for word in sentence:\n",
        "        vector.append(w2v[word])\n",
        "    return vector\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_shcpWloFJXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing text from a variety of different sources."
      ]
    },
    {
      "metadata": {
        "id": "VV3aJ1DtFJXf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's important to shuffle the text vectors before splitting them into test and train samples.   \n",
        "  \n",
        "This is done to avoid clumping text with similar context and style in the dataset because it can confuse the neural network during training.load_word2vec_format"
      ]
    },
    {
      "metadata": {
        "id": "i6B7j_jSFJXb",
        "colab_type": "code",
        "outputId": "51b9ee41-cd8b-4e64-a747-3ee56099b1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "# cache [['word', 'word',...'word']]\n",
        "# in generator, look them up\n",
        "data_concat = []\n",
        "!rm -f /content/10words.pk\n",
        "if not os.path.exists('/content/10words.pk'):\n",
        "    data_concat = []\n",
        "    total = 0\n",
        "    found = 0\n",
        "    with open('sentences.txt', 'r') as f:\n",
        "        for line in f:\n",
        "            total += 1\n",
        "            if total % 20000 == 0:\n",
        "                print(total)\n",
        "            #if len(data_concat) > 10000:\n",
        "            #    break\n",
        "            line = line.strip()\n",
        "            if line.count(' ') != 9:\n",
        "                continue\n",
        "            text_array = token_sent(line)\n",
        "            for sentence in text_array:\n",
        "                #print(sentence)\n",
        "                vect = wordify(sentence)\n",
        "                if vect != None and len(vect) == 10:\n",
        "                    data_concat.append(vect)\n",
        "                    #print(vect)\n",
        "\n",
        "#    total = 0\n",
        "#    found = 0\n",
        "#    for t in []: # [brown.words(), reuters.words(), gutenberg.words()]:\n",
        "#       text = split_into_sent(t)\n",
        "#        total += len(vect)\n",
        "#        vect = collect_sentences(text)\n",
        "#       data = [x for x in vect if len(x) == 10]\n",
        "#        for x in data:\n",
        "#            found += 1\n",
        "#            data_concat.append(list(itertools.chain.from_iterable(x)))\n",
        "    with open('/content/10words.pk', 'wb') as f:\n",
        "        pickle.dump(data_concat, f)\n",
        "else:\n",
        "    with open('/content/10words.pk', 'rb') as f:\n",
        "        data_concat = pickle.load(f)\n",
        "print('Total # of 10-word sentences: {}'.format(len(data_concat)))\n",
        "print(data_concat[0])\n",
        "print(data_concat[2])\n",
        "!ls -sh /content"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n",
            "40000\n",
            "60000\n",
            "80000\n",
            "100000\n",
            "120000\n",
            "140000\n",
            "160000\n",
            "180000\n",
            "200000\n",
            "220000\n",
            "240000\n",
            "260000\n",
            "280000\n",
            "300000\n",
            "320000\n",
            "340000\n",
            "360000\n",
            "380000\n",
            "400000\n",
            "Total # of 10-word sentences: 85806\n",
            "['a', 'blue', 'and', 'white', 'bathroom', 'with', 'butterfly', 'themed', 'wall', 'tiles']\n",
            "['the', 'vanity', 'contains', 'two', 'sinks', 'with', 'a', 'towel', 'for', 'each']\n",
            "total 9.5G\n",
            " 11M 10words.pk\t\t\t    22M sentences.txt\n",
            "242M annotations_trainval2014.zip  6.2G wiki.en.vec\n",
            " 64M captions_train2014.json\t   134M wiki.en.vec.kv\n",
            " 83M model.h5\t\t\t   2.9G wiki.en.vec.kv.vectors.npy\n",
            "4.0K sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "psRQhbSMFJXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = data_concat[10000:]\n",
        "test = data_concat[:10000]\n",
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)\n",
        "train = np.array(train)\n",
        "test = np.array(test)\n",
        "#del data_concat\n",
        "\n",
        "#add randomization of batch\n",
        "#model.fit_generator(generator(features, labels, batch_size), samples_per_epoch=50, nb_epoch=10\n",
        "def generator(sentences, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        batch_features = np.zeros((batch_size, embedding_size * len(sentences[0])))\n",
        "        for i in range(batch_size):\n",
        "            batch_features[i] = np.reshape(np.array(vectorize_sentence(sentences[index + i])), embedding_size * len(sentences[0]))\n",
        "        index += batch_size\n",
        "        if index >= len(sentences):\n",
        "            index = 0\n",
        "        yield batch_features, batch_features\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LLG9zMP0FJXn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Variational Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "WeRvlWKqFJXo",
        "colab_type": "code",
        "outputId": "12b5ecf2-95f9-476f-d645-57966c0d78b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2499
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "original_dim = 3000\n",
        "latent_dim = 1000\n",
        "intermediate_dim = 1200\n",
        "epochs=200\n",
        "epsilon_std = 1.0\n",
        "dist_weight = 1\n",
        "kl_weight = 1# 0.001\n",
        "learning_rate = 0.001\n",
        "opt = Nadam(lr=learning_rate)\n",
        "\n",
        "\n",
        "# Can only train on batch_size modulo data\n",
        "train = train[:(len(train) // batch_size) * batch_size]\n",
        "test = test[:(len(test) // batch_size) * batch_size]\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# we instantiate these layers separately so as to reuse them later\n",
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# placeholder loss\n",
        "def zero_loss(y_true, y_pred):\n",
        "    return K.zeros_like(y_pred)\n",
        "\n",
        "# Custom loss layer\n",
        "class CustomVariationalLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
        "        \n",
        "    def vae_loss(self, x, x_decoded_mean):\n",
        "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
        "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    def vae_lossX(self, x, x_decoded_mean):\n",
        "        #xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
        "        xent_loss = metrics.logcosh(x, x_decoded_mean)\n",
        "        kl_loss = K.mean(K.sum(- 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)))\n",
        "        return K.mean(dist_weight * xent_loss + kl_weight * kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        x_decoded_mean = inputs[1]\n",
        "        loss = self.vae_loss(x, x_decoded_mean)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        # we don't use this output, but it has to have the correct shape:\n",
        "        return K.ones_like(x)\n",
        "\n",
        "# separate break-out of \n",
        "def kl_loss(x, x_decoded_mean):\n",
        "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    kl_loss = kl_weight * kl_loss\n",
        "    return kl_loss\n",
        "\n",
        "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
        "vae = Model(x, [loss_layer])\n",
        "vae.compile(optimizer='rmsprop', loss=[zero_loss], metrics=[kl_loss])\n",
        "vae.summary()\n",
        "\n",
        "#checkpoint\n",
        "cp = [ModelCheckpoint(filepath=\"/content/model.h5\", verbose=1, save_best_only=True)]\n",
        "\n",
        "#train\n",
        "history = vae.fit_generator(generator(train, batch_size),\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=len(train)/batch_size,\n",
        "        validation_steps=len(test)/batch_size,\n",
        "        verbose=2,\n",
        "        validation_data=generator(test, batch_size), callbacks=cp)\n",
        "#model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
        "#                    steps_per_epoch=10000, epochs=10)\n",
        "\n",
        "for l in history.history.keys():\n",
        "    print(l)\n",
        "\n",
        "# build a model to project inputs on the latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# build a generator that can sample from the learned distribution\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (500, 3000)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (500, 1200)          3601200     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (500, 1000)          1201000     dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (500, 1000)          1201000     dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (500, 1000)          0           dense_12[0][0]                   \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (500, 1200)          1201200     lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (500, 3000)          3603000     dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_3 (Cus [(500, 3000), (500,  0           input_3[0][0]                    \n",
            "                                                                 dense_15[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 10,807,400\n",
            "Trainable params: 10,807,400\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            " - 13s - loss: -1.3167e+03 - kl_loss: 24.5003 - val_loss: -1.4916e+03 - val_kl_loss: 2.5134\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to -1491.64191, saving model to /content/model.h5\n",
            "Epoch 2/200\n",
            " - 12s - loss: -1.5100e+03 - kl_loss: 12.7323 - val_loss: -1.5754e+03 - val_kl_loss: 18.5780\n",
            "\n",
            "Epoch 00002: val_loss improved from -1491.64191 to -1575.35620, saving model to /content/model.h5\n",
            "Epoch 3/200\n",
            " - 13s - loss: -1.5753e+03 - kl_loss: 24.9090 - val_loss: -1.6195e+03 - val_kl_loss: 28.3345\n",
            "\n",
            "Epoch 00003: val_loss improved from -1575.35620 to -1619.47439, saving model to /content/model.h5\n",
            "Epoch 4/200\n",
            " - 13s - loss: -1.6196e+03 - kl_loss: 34.6416 - val_loss: -1.6544e+03 - val_kl_loss: 36.6901\n",
            "\n",
            "Epoch 00004: val_loss improved from -1619.47439 to -1654.44274, saving model to /content/model.h5\n",
            "Epoch 5/200\n",
            " - 12s - loss: -1.6543e+03 - kl_loss: 42.6422 - val_loss: -1.6867e+03 - val_kl_loss: 43.5147\n",
            "\n",
            "Epoch 00005: val_loss improved from -1654.44274 to -1686.67544, saving model to /content/model.h5\n",
            "Epoch 6/200\n",
            " - 13s - loss: -1.6853e+03 - kl_loss: 49.9331 - val_loss: -1.7164e+03 - val_kl_loss: 50.5767\n",
            "\n",
            "Epoch 00006: val_loss improved from -1686.67544 to -1716.38046, saving model to /content/model.h5\n",
            "Epoch 7/200\n",
            " - 13s - loss: -1.7130e+03 - kl_loss: 56.5385 - val_loss: -1.7400e+03 - val_kl_loss: 53.9167\n",
            "\n",
            "Epoch 00007: val_loss improved from -1716.38046 to -1739.95510, saving model to /content/model.h5\n",
            "Epoch 8/200\n",
            " - 12s - loss: -1.7379e+03 - kl_loss: 62.3493 - val_loss: -1.7574e+03 - val_kl_loss: 60.2033\n",
            "\n",
            "Epoch 00008: val_loss improved from -1739.95510 to -1757.43232, saving model to /content/model.h5\n",
            "Epoch 9/200\n",
            " - 13s - loss: -1.7600e+03 - kl_loss: 67.4145 - val_loss: -1.7780e+03 - val_kl_loss: 68.0328\n",
            "\n",
            "Epoch 00009: val_loss improved from -1757.43232 to -1778.02587, saving model to /content/model.h5\n",
            "Epoch 10/200\n",
            " - 12s - loss: -1.7822e+03 - kl_loss: 72.1771 - val_loss: -1.7977e+03 - val_kl_loss: 71.0829\n",
            "\n",
            "Epoch 00010: val_loss improved from -1778.02587 to -1797.65834, saving model to /content/model.h5\n",
            "Epoch 11/200\n",
            " - 12s - loss: -1.8011e+03 - kl_loss: 76.5611 - val_loss: -1.8099e+03 - val_kl_loss: 74.7157\n",
            "\n",
            "Epoch 00011: val_loss improved from -1797.65834 to -1809.86866, saving model to /content/model.h5\n",
            "Epoch 12/200\n",
            " - 12s - loss: -1.8173e+03 - kl_loss: 80.2020 - val_loss: -1.8231e+03 - val_kl_loss: 73.3598\n",
            "\n",
            "Epoch 00012: val_loss improved from -1809.86866 to -1823.13951, saving model to /content/model.h5\n",
            "Epoch 13/200\n",
            " - 13s - loss: -1.8328e+03 - kl_loss: 83.6858 - val_loss: -1.8354e+03 - val_kl_loss: 82.9489\n",
            "\n",
            "Epoch 00013: val_loss improved from -1823.13951 to -1835.39498, saving model to /content/model.h5\n",
            "Epoch 14/200\n",
            " - 12s - loss: -1.8470e+03 - kl_loss: 86.9585 - val_loss: -1.8435e+03 - val_kl_loss: 86.6199\n",
            "\n",
            "Epoch 00014: val_loss improved from -1835.39498 to -1843.53741, saving model to /content/model.h5\n",
            "Epoch 15/200\n",
            " - 12s - loss: -1.8612e+03 - kl_loss: 89.7736 - val_loss: -1.8528e+03 - val_kl_loss: 93.3490\n",
            "\n",
            "Epoch 00015: val_loss improved from -1843.53741 to -1852.80550, saving model to /content/model.h5\n",
            "Epoch 16/200\n",
            " - 13s - loss: -1.8741e+03 - kl_loss: 92.5363 - val_loss: -1.8687e+03 - val_kl_loss: 86.8503\n",
            "\n",
            "Epoch 00016: val_loss improved from -1852.80550 to -1868.66417, saving model to /content/model.h5\n",
            "Epoch 17/200\n",
            " - 12s - loss: -1.8866e+03 - kl_loss: 94.7113 - val_loss: -1.8802e+03 - val_kl_loss: 90.0306\n",
            "\n",
            "Epoch 00017: val_loss improved from -1868.66417 to -1880.15635, saving model to /content/model.h5\n",
            "Epoch 18/200\n",
            " - 13s - loss: -1.8976e+03 - kl_loss: 96.6336 - val_loss: -1.8921e+03 - val_kl_loss: 95.5474\n",
            "\n",
            "Epoch 00018: val_loss improved from -1880.15635 to -1892.10590, saving model to /content/model.h5\n",
            "Epoch 19/200\n",
            " - 12s - loss: -1.9080e+03 - kl_loss: 98.5116 - val_loss: -1.9008e+03 - val_kl_loss: 85.9994\n",
            "\n",
            "Epoch 00019: val_loss improved from -1892.10590 to -1900.81455, saving model to /content/model.h5\n",
            "Epoch 20/200\n",
            " - 12s - loss: -1.9185e+03 - kl_loss: 99.9329 - val_loss: -1.9088e+03 - val_kl_loss: 102.3157\n",
            "\n",
            "Epoch 00020: val_loss improved from -1900.81455 to -1908.76915, saving model to /content/model.h5\n",
            "Epoch 21/200\n",
            " - 13s - loss: -1.9282e+03 - kl_loss: 101.3966 - val_loss: -1.9171e+03 - val_kl_loss: 101.6536\n",
            "\n",
            "Epoch 00021: val_loss improved from -1908.76915 to -1917.11453, saving model to /content/model.h5\n",
            "Epoch 22/200\n",
            " - 13s - loss: -1.9383e+03 - kl_loss: 102.5952 - val_loss: -1.9284e+03 - val_kl_loss: 91.9473\n",
            "\n",
            "Epoch 00022: val_loss improved from -1917.11453 to -1928.42057, saving model to /content/model.h5\n",
            "Epoch 23/200\n",
            " - 12s - loss: -1.9481e+03 - kl_loss: 103.7599 - val_loss: -1.9325e+03 - val_kl_loss: 101.9090\n",
            "\n",
            "Epoch 00023: val_loss improved from -1928.42057 to -1932.52714, saving model to /content/model.h5\n",
            "Epoch 24/200\n",
            " - 12s - loss: -1.9574e+03 - kl_loss: 104.6863 - val_loss: -1.9441e+03 - val_kl_loss: 96.4290\n",
            "\n",
            "Epoch 00024: val_loss improved from -1932.52714 to -1944.11314, saving model to /content/model.h5\n",
            "Epoch 25/200\n",
            " - 12s - loss: -1.9668e+03 - kl_loss: 105.5152 - val_loss: -1.9515e+03 - val_kl_loss: 98.8496\n",
            "\n",
            "Epoch 00025: val_loss improved from -1944.11314 to -1951.52335, saving model to /content/model.h5\n",
            "Epoch 26/200\n",
            " - 13s - loss: -1.9758e+03 - kl_loss: 106.3582 - val_loss: -1.9542e+03 - val_kl_loss: 102.9799\n",
            "\n",
            "Epoch 00026: val_loss improved from -1951.52335 to -1954.16288, saving model to /content/model.h5\n",
            "Epoch 27/200\n",
            " - 12s - loss: -1.9846e+03 - kl_loss: 106.9770 - val_loss: -1.9666e+03 - val_kl_loss: 103.8863\n",
            "\n",
            "Epoch 00027: val_loss improved from -1954.16288 to -1966.55869, saving model to /content/model.h5\n",
            "Epoch 28/200\n",
            " - 13s - loss: -1.9926e+03 - kl_loss: 107.5426 - val_loss: -1.9726e+03 - val_kl_loss: 106.3863\n",
            "\n",
            "Epoch 00028: val_loss improved from -1966.55869 to -1972.59261, saving model to /content/model.h5\n",
            "Epoch 29/200\n",
            " - 13s - loss: -2.0007e+03 - kl_loss: 108.0735 - val_loss: -1.9738e+03 - val_kl_loss: 96.4504\n",
            "\n",
            "Epoch 00029: val_loss improved from -1972.59261 to -1973.78137, saving model to /content/model.h5\n",
            "Epoch 30/200\n",
            " - 13s - loss: -2.0082e+03 - kl_loss: 108.4639 - val_loss: -1.9876e+03 - val_kl_loss: 100.2426\n",
            "\n",
            "Epoch 00030: val_loss improved from -1973.78137 to -1987.61558, saving model to /content/model.h5\n",
            "Epoch 31/200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZ1UrMWXYFjM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the training curves"
      ]
    },
    {
      "metadata": {
        "id": "n69Xl4HgYJb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_kl_loss'])\n",
        "plt.title('val loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['val_loss'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMj_3TpwacUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_kl_loss'])\n",
        "plt.title('val kl_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['val_kl_loss'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xEThXyL4FJXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating Text From Latent Space"
      ]
    },
    {
      "metadata": {
        "id": "rUF_JCx_FJXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# some matrix magic\n",
        "def sent_parse(sentence, mat_shape):\n",
        "    data_concat = []\n",
        "    word_vecs = vectorize_sentences(sentence)\n",
        "    for x in word_vecs:\n",
        "        data_concat.append(list(itertools.chain.from_iterable(x)))\n",
        "    zero_matr = np.zeros(mat_shape)\n",
        "    zero_matr[0] = np.array(data_concat)\n",
        "    return zero_matr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "boTL4PUTFJXy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input: original dimension sentence vector\n",
        "# output: text\n",
        "def print_sentence_with_w2v(sent_vect):\n",
        "    word_sent = ''\n",
        "    tocut = sent_vect\n",
        "    for i in range (int(len(sent_vect)/300)):\n",
        "        word_sent += w2v.most_similar(positive=[tocut[:300]], topn=1)[0][0]\n",
        "        word_sent += ' '\n",
        "        tocut = tocut[300:]\n",
        "    print(word_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ7YMvsZFJX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input: encoded sentence vector\n",
        "# output: encoded sentence vector in dataset with highest cosine similarity\n",
        "def find_similar_encoding(sent_vect):\n",
        "    all_cosine = []\n",
        "    for sent in sent_encoded:\n",
        "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
        "        all_cosine.append(result)\n",
        "    data_array = np.array(all_cosine)\n",
        "    maximum = data_array.argsort()[-3:][::-1][1]\n",
        "    new_vec = sent_encoded[maximum]\n",
        "    return new_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVV55SEBFJX5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input: two points, integer n\n",
        "# output: n equidistant points on the line between the input points (inclusive)\n",
        "def shortest_homology(point_one, point_two, num):\n",
        "    dist_vec = point_two - point_one\n",
        "    sample = np.linspace(0, 1, num, endpoint = True)\n",
        "    hom_sample = []\n",
        "    for s in sample:\n",
        "        hom_sample.append(point_one + s * dist_vec)\n",
        "    return hom_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2CNE5ZdFJX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input: two written sentences, VAE batch-size, dimension of VAE input\n",
        "# output: the function embeds the sentences in latent-space, and then prints their generated text representations\n",
        "# along with the text representations of several points in between them\n",
        "def sent_2_sent(sent1,sent2, batch, dim):\n",
        "    a = sent_parse([sent1], (batch,dim))\n",
        "    b = sent_parse([sent2], (batch,dim))\n",
        "    encode_a = encoder.predict(a, batch_size = batch)\n",
        "    encode_b = encoder.predict(b, batch_size = batch)\n",
        "    test_hom = hom_shortest(encode_a[0], encode_b[0], 5)\n",
        "    \n",
        "    for point in test_hom:\n",
        "        p = generator.predict(np.array([point]))[0]\n",
        "        print_sentence(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsJ8ujOzFJYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Printing sentences from the training set and comparing them with the original will test whether the custom print function works properly."
      ]
    },
    {
      "metadata": {
        "id": "vlz-dEmZFJYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_sentence_with_w2v(train[1])\n",
        "print_sentence_with_w2v(train[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRX1AVseFJYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The encoder takes the training set of sentence vectors (concatenanted word vectors) and embeds them into a lower dimensional vector space."
      ]
    },
    {
      "metadata": {
        "id": "kW0gQZFFFJYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_encoded = encoder.predict(np.array(train), batch_size = 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YLFu14j-FJYN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The decoder takes the list of latent dimensional encodings from above and turns them back into vectors of their original dimension."
      ]
    },
    {
      "metadata": {
        "id": "ozh2qthcFJYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_decoded = generator.predict(sent_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4DkI4kyFJYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The encoder trained above embeds sentences (concatenated word vetors) into a lower dimensional space. The code below takes two of these lower dimensional sentence representations and finds five points between them. It then uses the trained decoder to project these five points into the higher, original, dimensional space. Finally, it reveals the text represented by the five generated sentence vectors by taking each word vector concatenated inside and finding the text associated with it in the word2vec used during preprocessing."
      ]
    },
    {
      "metadata": {
        "id": "2Rj7JcK3FJYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_hom = shortest_homology(sent_encoded[3], sent_encoded[10], 5)\n",
        "for point in test_hom:\n",
        "    p = generator.predict(np.array([point]))[0]\n",
        "    print_sentence_with_w2v(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4F2NqZ-eFJYV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code below does the same thing, with one important difference. After sampling equidistant points in the latent space between two sentence embeddings, it finds the embeddings from our encoded dataset those points are most similar to. It then prints the text associated with those vectors.\n",
        "  \n",
        "This allows us to explore how the Variational Autoencoder clusters our dataset of sentences in latent space. It lets us investigate whether sentences with similar concepts or grammatical styles are represented in similar areas of the lower dimensional space."
      ]
    },
    {
      "metadata": {
        "id": "z8EXTcpCFJYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_hom = shortest_homology(sent_encoded[2], sent_encoded[1500], 20)\n",
        "for point in test_hom:\n",
        "    p = generator.predict(np.array([find_similar_encoding(point)]))[0]\n",
        "    print_sentence_with_w2v(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMtxxG9KeWer",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ]
    },
    {
      "metadata": {
        "id": "e8VQqEE_eZUk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adventure_maze = [\n",
        "    #'before you is a twisty maze of passages all alike',\n",
        "    #'you see now a twisty maze of passages all like',\n",
        "    #'a maze of twisty passages all alike stretches before you',\n",
        "    #'a twisty maze all alike is in front of you',\n",
        "    #'twisty passages forming a maze stretch in front of you',\n",
        "    #'you come upon a maze of twisty passages all alike',\n",
        "    'you are in a maze of twisty little passages now',\n",
        "    'you are in a little maze of twisting passages now',\n",
        "    'you are in a maze of twisting little passages now',\n",
        "    'you are in a little maze of twisty passages now',\n",
        "    'you are in a twisting maze of little passages now',\n",
        "    'you are in a twisting little maze of passages now',\n",
        "    'you are in a twisty little maze of passages now',\n",
        "    'you are in a twisty maze of little passages now',\n",
        "    'you are in a little twisty maze of passages now',\n",
        "    'you are in a maze of little twisting passages now',\n",
        "    'you are in a maze of little twisty passages now'\n",
        "]\n",
        "maze_embeds = []\n",
        "maze_vect = vectorize_sentences(adventure_maze)\n",
        "for m in maze_vect:\n",
        "    maze_embeds.append(np.reshape(m, (3000)))\n",
        "maze_grind = np.array(maze_embeds)\n",
        "print(maze_grind.shape)\n",
        "maze_predicted = encoder.predict(maze_grind, batch_size = 1)\n",
        "maze_decoded = generator.predict(maze_predicted, batch_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DE1oxAi6msxj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot original spread and Variational embeddings\n",
        "First, create a 2D visualization of the embedding space. "
      ]
    },
    {
      "metadata": {
        "id": "CUfI0boTsPFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downsample_orig = np.random.random((original_dim, 2))\n",
        "downsample_latent = np.random.random((latent_dim, 2))\n",
        "maze_grind_2d = [[]] * len(adventure_maze)\n",
        "maze_predict_2d = [[]] * len(adventure_maze)\n",
        "for i in range(len(adventure_maze)):\n",
        "    maze_grind_2d[i] = maze_grind[i].dot(downsample_orig)\n",
        "    maze_predict_2d[i] = maze_predicted[i].dot(downsample_latent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNCj5v6_2PVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pca_orig = PCA(n_components=2)\n",
        "pca_orig.fit(np.array(train))\n",
        "pca_predict = PCA(n_components=2)\n",
        "pca_predict.fit(sent_encoded)\n",
        "pca_decode = PCA(n_components=2)\n",
        "pca_decode.fit(sent_decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sqyesg7K9RZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maze_orig_2d = pca_orig.transform(np.array(maze_grind))\n",
        "maze_predict_2d = pca_predict.transform(np.array(maze_predicted))\n",
        "maze_decode_2d = pca_decode.transform(np.array(maze_decoded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQF-cvLRm81z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
        "for xy in maze_grind_2d:\n",
        "    ax1.scatter(xy[0], xy[1])\n",
        "ax1.set_title('Original')\n",
        "ax2.set_title('VAE Latent')\n",
        "ax2.set_title('Decoded')\n",
        "for xy in maze_predict_2d:\n",
        "    ax2.scatter(xy[0], xy[1])\n",
        "for xy in maze_decode_2d:\n",
        "    ax3.scatter(xy[0], xy[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPDJYMjN9QCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-EzqVrAi-z-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  corr = np.log(corr)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\"\n",
        "  )\n",
        "\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5uXy4yEmzft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_similarity(adventure_maze, maze_grind, 90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z7_wEAUM4Qqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_similarity(adventure_maze, maze_predicted, 90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64BCsHVE3G6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}